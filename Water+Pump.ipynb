{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump it UP!\n",
    "## Data loading and Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_l = pd.read_csv(\"./train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_p = pd.read_csv(\"water_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = test_p.iloc[:, :-3] #remove the last 3 varaiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1 = pd.merge(train,train_l, on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle NA's Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This should strip the empty spaces but I'm not sure if it happened\n",
    "categorical_features = pd.DataFrame(train_1.describe(include = ['O'])).columns\n",
    "\n",
    "for c in categorical_features:\n",
    "    train_1.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop some columns we don't need or are duplicated\n",
    "cols = ('Index','id','gps_height','wpt_name','subvillage','num_private','region',\n",
    "            'lga','ward','public_meeting','recorded_by','scheme_name','extraction_type', \n",
    "            'extraction_type_group','management_group','payment','quality_group','quantity_group',\n",
    "            'source_class','waterpoint_type','basin')\n",
    "#check gps hight \n",
    "for c in cols :\n",
    "    train_1.drop(c,inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change date_Recorded to datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "datedf = train_1['date_recorded']\n",
    "train_1['date_recorded'] = pd.to_datetime(train_1['date_recorded'], yearfirst = True, format = '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden NA's and false 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_tsh               41639\n",
      "date_recorded                0\n",
      "funder                       0\n",
      "installer                    0\n",
      "longitude                 1812\n",
      "latitude                     0\n",
      "region_code                  0\n",
      "district_code               23\n",
      "population               21381\n",
      "scheme_management            0\n",
      "permit                   38852\n",
      "construction_year        20709\n",
      "extraction_type_class        0\n",
      "management                   0\n",
      "payment_type                 0\n",
      "water_quality                0\n",
      "quantity                     0\n",
      "source                       0\n",
      "source_type                  0\n",
      "waterpoint_type_group        0\n",
      "status_group                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Which columns are suspects to have false 0's that are actually na's?\n",
    "print((train_1 == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert 0's to Na's\n",
    "nas = ('construction_year', 'amount_tsh', 'longitude', 'district_code', 'permit', 'construction_year') \n",
    "\n",
    "for i in train_1.columns:\n",
    "    if i in nas:\n",
    "        train_1.replace(0, np.NaN, inplace = True)\n",
    "        \n",
    "## LOOP IS NOT WORKING. IT REMOVES ALL 0'S INSTEAD OF THE ONES IN THE NA LIST ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_tsh               0\n",
      "date_recorded            0\n",
      "funder                   0\n",
      "installer                0\n",
      "longitude                0\n",
      "latitude                 0\n",
      "region_code              0\n",
      "district_code            0\n",
      "population               0\n",
      "scheme_management        0\n",
      "permit                   0\n",
      "construction_year        0\n",
      "extraction_type_class    0\n",
      "management               0\n",
      "payment_type             0\n",
      "water_quality            0\n",
      "quantity                 0\n",
      "source                   0\n",
      "source_type              0\n",
      "waterpoint_type_group    0\n",
      "status_group             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Which columns are suspects to have false 0's that are actually na's?\n",
    "print((train_1 == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WORLDBANK', 100, 141),\n",
       " ('WORLDBANK', 100, 280),\n",
       " ('WORLDBANK', 100, 304),\n",
       " ('WORLDBANK', 100, 349),\n",
       " ('WORLDBANK', 100, 399)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "query = 'WORLDBANK'\n",
    "choices = train_1['installer']\n",
    "# Get a list of matches ordered by score, default limit to 5\n",
    "process.extract(query, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001346597316904846"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difflib import SequenceMatcher as SM\n",
    "SM(None, query, choices).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incomplete Cases and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0        1\n",
      "permit             41908  float64\n",
      "amount_tsh         41639  float64\n",
      "population         21381  float64\n",
      "construction_year  20709  float64\n",
      "longitude           1812  float64\n",
      "district_code         23  float64\n",
      "There are 6 columns with missing values\n"
     ]
    }
   ],
   "source": [
    "objects = []\n",
    "for i in train_1.columns:\n",
    "    if train_1[i].dtype == object:\n",
    "        objects.append(i)\n",
    "\n",
    "train_1.update(train_1[objects].fillna('None'))\n",
    "\n",
    "nulls = np.sum(train_1.isnull())\n",
    "nullcols = nulls.loc[(nulls != 0)]\n",
    "dtypes = train_1.dtypes\n",
    "dtypes2 = dtypes.loc[(nulls != 0)]\n",
    "info = pd.concat([nullcols, dtypes2], axis=1).sort_values(by=0, ascending=False)\n",
    "print(info)\n",
    "print(\"There are\", len(nullcols), \"columns with missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set incomplete cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "installer                1903\n",
       "funder                   1889\n",
       "scheme_management          13\n",
       "management                 12\n",
       "source                     10\n",
       "source_type                 7\n",
       "payment_type                7\n",
       "extraction_type_class       7\n",
       "waterpoint_type_group       6\n",
       "quantity                    5\n",
       "status_group                3\n",
       "water_quality               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create object with datatype categorical\n",
    "objects3 = []\n",
    "for i in train_1.columns:\n",
    "    if train_1[i].dtype == 'object':\n",
    "        objects3.append(i)\n",
    "        \n",
    "print(\"Training Set incomplete cases\")\n",
    "\n",
    "sums_train_1 = train_1[objects3].apply(lambda x: len(np.unique(x)))\n",
    "sums_train_1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set incomplete cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "longitude            59327\n",
       "latitude             57517\n",
       "permit               41909\n",
       "amount_tsh           41736\n",
       "population           22429\n",
       "construction_year    20763\n",
       "district_code           42\n",
       "region_code             27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create object with datatype integer and check incomplete cases\n",
    "num1 = []\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "for i in train_1.columns:\n",
    "    if train_1[i].dtype in numeric_dtypes:\n",
    "        num1.append(i)\n",
    "        \n",
    "print(\"Training Set incomplete cases\")\n",
    "\n",
    "sums_train_1 = train_1[num1].apply(lambda x: len(np.unique(x)))\n",
    "sums_train_1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove skewness and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>region_code</th>\n",
       "      <td>3.173738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.152033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       skew\n",
       "region_code        3.173738\n",
       "latitude          -0.152033\n",
       "amount_tsh              NaN\n",
       "longitude               NaN\n",
       "district_code           NaN\n",
       "population              NaN\n",
       "permit                  NaN\n",
       "construction_year       NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in train_1.columns:\n",
    "    if train_1[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "        \n",
    "skew_train_1 = train_1[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "skews = pd.DataFrame({'skew': skew_train_1})\n",
    "skews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>41908</td>\n",
       "      <td>0.705522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>41639</td>\n",
       "      <td>0.700993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>21381</td>\n",
       "      <td>0.359949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>20709</td>\n",
       "      <td>0.348636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1812</td>\n",
       "      <td>0.030505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_recorded</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Total   Percent\n",
       "permit             41908  0.705522\n",
       "amount_tsh         41639  0.700993\n",
       "population         21381  0.359949\n",
       "construction_year  20709  0.348636\n",
       "longitude           1812  0.030505\n",
       "district_code         23  0.000387\n",
       "source_type            0  0.000000\n",
       "date_recorded          0  0.000000\n",
       "funder                 0  0.000000\n",
       "installer              0  0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check percentages of NA's\n",
    "total = train_1.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_1.isnull().sum()/train_1.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total,percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Impute NA's with median\n",
    "train_1['construction_year'].fillna(train_1['construction_year'].mean(), inplace=True)\n",
    "#Total static head (amount water available to waterpoint)\n",
    "train_1['amount_tsh'].fillna(train_1['amount_tsh'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fancyimpute import KNN\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "newdf = train_1.select_dtypes(include=numerics)\n",
    "\n",
    "        # I now run fancyimpute KNN - it returns a np.array which I store as a pandas dataframe\n",
    "#df_complete = pd.DataFrame(KNN(3).complete(newdf))\n",
    "#df_complete.to_csv('clean_numerics.csv')\n",
    "\n",
    "df_complete = pd.read_csv('clean_numerics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_recorded</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Total  Percent\n",
       "amount_tsh                 0      0.0\n",
       "construction_year          0      0.0\n",
       "date_recorded              0      NaN\n",
       "district_code              0      0.0\n",
       "extraction_type_class      0      NaN\n",
       "funder                     0      NaN\n",
       "installer                  0      NaN\n",
       "latitude                   0      0.0\n",
       "longitude                  0      0.0\n",
       "management                 0      NaN\n",
       "payment_type               0      NaN\n",
       "permit                     0      0.0\n",
       "population                 0      0.0\n",
       "quantity                   0      NaN\n",
       "region_code                0      0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rearrange dataset\n",
    "df_complete.columns = newdf.columns\n",
    "df_complete.index = newdf.index\n",
    "\n",
    "#replace values in original df\n",
    "train_1['amount_tsh'] = df_complete['amount_tsh'].values\n",
    "train_1['longitude'] = df_complete['longitude'].values\n",
    "train_1['latitude'] = df_complete['latitude'].values\n",
    "train_1['region_code'] = df_complete['region_code'].values\n",
    "train_1['district_code'] = df_complete['district_code'].values\n",
    "train_1['population'] = df_complete['population'].values\n",
    "train_1['permit'] = df_complete['permit'].values\n",
    "train_1['construction_year'] = df_complete['construction_year'].values\n",
    "\n",
    "#Sanity check\n",
    "total = train_1.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_complete.isnull().sum()/df_complete.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total,percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5*features['HalfBath']) + \n",
    "                               features['BsmtFullBath'] + (0.5*features['BsmtHalfBath']))\n",
    "\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                             features['WoodDeckSF'])\n",
    "\n",
    "\n",
    "#simplified features\n",
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove vars from test dataset\n",
    "cols = ('id','gps_height','wpt_name','subvillage','num_private','region',\n",
    "            'lga','ward','public_meeting','recorded_by','scheme_name','extraction_type', \n",
    "            'extraction_type_group','management_group','payment','quality_group','quantity_group',\n",
    "            'source_class','waterpoint_type', 'basin')\n",
    "\n",
    "for c in cols :\n",
    "    test.drop(c,inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change date_Recorded to datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "datedf = test['date_recorded']\n",
    "test['date_recorded'] = pd.to_datetime(test['date_recorded'], yearfirst = True, format = '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: \n",
      "\n",
      "Number of columns: 21\n",
      "Number of rows: 59400\n",
      "\n",
      "Test Data: \n",
      "\n",
      "Number of columns: 20\n",
      "Number of rows: 14850\n"
     ]
    }
   ],
   "source": [
    "#summary of datasets\n",
    "print('Train Data: \\n')\n",
    "print(\"Number of columns: \"+ str(train_1.shape[1]))\n",
    "print(\"Number of rows: \"+ str(train_1.shape[0]))\n",
    "print('\\nTest Data: \\n')\n",
    "print(\"Number of columns: \"+ str(test.shape[1]))\n",
    "print(\"Number of rows: \"+ str(test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Na Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount_tsh               10410\n",
      "date_recorded                0\n",
      "funder                       0\n",
      "installer                    0\n",
      "longitude                  457\n",
      "latitude                     0\n",
      "region_code                  0\n",
      "district_code                4\n",
      "population                5453\n",
      "scheme_management            0\n",
      "permit                    9754\n",
      "construction_year         5260\n",
      "extraction_type_class        0\n",
      "management                   0\n",
      "payment_type                 0\n",
      "water_quality                0\n",
      "quantity                     0\n",
      "source                       0\n",
      "source_type                  0\n",
      "waterpoint_type_group        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Which columns are suspects to have false 0's that are actually na's?\n",
    "print((test == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert 0's to Na's\n",
    "nas = ('construction_year', 'amount_tsh', 'longitude', 'district_code', 'permit', 'construction_year') \n",
    "\n",
    "for i in test.columns:\n",
    "    if i in nas:\n",
    "        test.replace(0, np.NaN, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0        1\n",
      "permit             10491  float64\n",
      "amount_tsh         10410  float64\n",
      "population          5453  float64\n",
      "construction_year   5260  float64\n",
      "longitude            457  float64\n",
      "district_code          4  float64\n",
      "There are 6 columns with missing values\n"
     ]
    }
   ],
   "source": [
    "objects = []\n",
    "for i in test.columns:\n",
    "    if test[i].dtype == object:\n",
    "        objects.append(i)\n",
    "\n",
    "test.update(test[objects].fillna('None'))\n",
    "nulls = np.sum(test.isnull())\n",
    "nullcols = nulls.loc[(nulls != 0)]\n",
    "dtypes = test.dtypes\n",
    "dtypes2 = dtypes.loc[(nulls != 0)]\n",
    "info = pd.concat([nullcols, dtypes2], axis=1).sort_values(by=0, ascending=False)\n",
    "print(info)\n",
    "print(\"There are\", len(nullcols), \"columns with missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set incomplete cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "funder                   976\n",
       "installer                910\n",
       "management                12\n",
       "scheme_management         12\n",
       "source                    10\n",
       "source_type                7\n",
       "payment_type               7\n",
       "extraction_type_class      7\n",
       "waterpoint_type_group      6\n",
       "quantity                   5\n",
       "water_quality              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create object with datatype categorical\n",
    "objects3 = []\n",
    "for i in test.columns:\n",
    "    if test[i].dtype == 'object':\n",
    "        objects3.append(i)\n",
    "        \n",
    "print(\"Training Set incomplete cases\")\n",
    "\n",
    "sums_test = test[objects3].apply(lambda x: len(np.unique(x)))\n",
    "sums_test.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distinct cases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "longitude            14846\n",
       "latitude             14390\n",
       "permit               10492\n",
       "amount_tsh           10477\n",
       "population            6089\n",
       "construction_year     5314\n",
       "region_code             26\n",
       "district_code           23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create object with datatype integer and check incomplete cases\n",
    "num1 = []\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "for i in test.columns:\n",
    "    if test[i].dtype in numeric_dtypes:\n",
    "        num1.append(i)\n",
    "print(\"Training distinct cases\")\n",
    "sums_test = test[num1].apply(lambda x: len(np.unique(x)))\n",
    "sums_test.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>region_code</th>\n",
       "      <td>3.200850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.156223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       skew\n",
       "region_code        3.200850\n",
       "latitude          -0.156223\n",
       "amount_tsh              NaN\n",
       "longitude               NaN\n",
       "district_code           NaN\n",
       "population              NaN\n",
       "permit                  NaN\n",
       "construction_year       NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in test.columns:\n",
    "    if test[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_test = test[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "skews = pd.DataFrame({'skew': skew_test})\n",
    "skews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>10491</td>\n",
       "      <td>0.706465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>10410</td>\n",
       "      <td>0.701010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>5453</td>\n",
       "      <td>0.367205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>5260</td>\n",
       "      <td>0.354209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>457</td>\n",
       "      <td>0.030774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_recorded</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Total   Percent\n",
       "permit             10491  0.706465\n",
       "amount_tsh         10410  0.701010\n",
       "population          5453  0.367205\n",
       "construction_year   5260  0.354209\n",
       "longitude            457  0.030774\n",
       "district_code          4  0.000269\n",
       "date_recorded          0  0.000000\n",
       "funder                 0  0.000000\n",
       "installer              0  0.000000\n",
       "latitude               0  0.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check percentages of NA's\n",
    "total = test.isnull().sum().sort_values(ascending=False)\n",
    "percent = (test.isnull().sum()/test.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total,percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Impute NA's with median\n",
    "test['construction_year'].fillna(test['construction_year'].mean(), inplace=True)\n",
    "#Total static head (amount water available to waterpoint)\n",
    "test['amount_tsh'].fillna(test['amount_tsh'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data for test\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "newdf = test.select_dtypes(include=numerics)\n",
    "#df_complete = pd.DataFrame(KNN(3).complete(newdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amount_tsh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>construction_year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_recorded</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Total  Percent\n",
       "amount_tsh                 0      0.0\n",
       "construction_year          0      0.0\n",
       "date_recorded              0      NaN\n",
       "district_code              0      0.0\n",
       "extraction_type_class      0      NaN\n",
       "funder                     0      NaN\n",
       "installer                  0      NaN\n",
       "latitude                   0      0.0\n",
       "longitude                  0      0.0\n",
       "management                 0      NaN\n",
       "payment_type               0      NaN\n",
       "permit                     0      0.0\n",
       "population                 0      0.0\n",
       "quantity                   0      NaN\n",
       "region_code                0      0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_complete.to_csv('clean_numerics_test.csv')\n",
    "df_complete = pd.read_csv('clean_numerics_test.csv')\n",
    "#Rearrange dataset\n",
    "df_complete.columns = newdf.columns\n",
    "df_complete.index = newdf.index\n",
    "\n",
    "#replace values in original df\n",
    "test['amount_tsh'] = df_complete['amount_tsh'].values\n",
    "test['longitude'] = df_complete['longitude'].values\n",
    "test['latitude'] = df_complete['latitude'].values\n",
    "test['region_code'] = df_complete['region_code'].values\n",
    "test['district_code'] = df_complete['district_code'].values\n",
    "test['population'] = df_complete['population'].values\n",
    "test['permit'] = df_complete['permit'].values\n",
    "test['construction_year'] = df_complete['construction_year'].values\n",
    "\n",
    "#Sanity check\n",
    "total = test.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_complete.isnull().sum()/df_complete.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total,percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: \n",
      "\n",
      "Index(['funder', 'installer', 'scheme_management', 'extraction_type_class',\n",
      "       'management', 'payment_type', 'water_quality', 'quantity', 'source',\n",
      "       'source_type', 'waterpoint_type_group', 'status_group'],\n",
      "      dtype='object')\n",
      "Categorical features: \n",
      "\n",
      "Index(['funder', 'installer', 'scheme_management', 'extraction_type_class',\n",
      "       'management', 'payment_type', 'water_quality', 'quantity', 'source',\n",
      "       'source_type', 'waterpoint_type_group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Check categoricals\n",
    "categorical_features = pd.DataFrame(train_1.describe(include = ['O'])).columns\n",
    "print('Categorical features: \\n')\n",
    "print(str(categorical_features))\n",
    "\n",
    "categorical_features = pd.DataFrame(test.describe(include = ['O'])).columns\n",
    "print('Categorical features: \\n')\n",
    "print(str(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for column in ['payment_type', 'quantity'] :\n",
    "    #dummies = pd.get_dummies(train_1[column])\n",
    "    #train_1[dummies.columns] = dummies\n",
    "    \n",
    "#for column in ['payment_type', 'quantity'] :\n",
    "    #dummies = pd.get_dummies(test[column])\n",
    "    #test[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#labelencoding train\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in ('payment_type', 'quantity','scheme_management','extraction_type_class','water_quality', 'quantity', 'waterpoint_type_group', 'status_group', 'source', 'source_type', \n",
    "            'management', 'funder', 'installer'):\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_1[col].values)) \n",
    "    train_1[col] = lbl.transform(list(train_1[col].values))\n",
    "\n",
    "#labelencoding test\n",
    "\n",
    "for col in ('payment_type', 'quantity','scheme_management','extraction_type_class','water_quality', 'quantity', 'waterpoint_type_group', 'source', 'source_type', 'management', \n",
    "           'funder', 'installer'):\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(test[col].values)) \n",
    "    test[col] = lbl.transform(list(test[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: \n",
      "\n",
      "Number of columns: 21\n",
      "Number of rows: 59400\n",
      "\n",
      "Test Data: \n",
      "\n",
      "Number of columns: 20\n",
      "Number of rows: 14850\n"
     ]
    }
   ],
   "source": [
    "#summary of datasets\n",
    "print('Train Data: \\n')\n",
    "print(\"Number of columns: \"+ str(train_1.shape[1]))\n",
    "print(\"Number of rows: \"+ str(train_1.shape[0]))\n",
    "print('\\nTest Data: \\n')\n",
    "print(\"Number of columns: \"+ str(test.shape[1]))\n",
    "print(\"Number of rows: \"+ str(test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take out y\n",
    "y = train_1['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_1.drop(['status_group', 'date_recorded', 'latitude', 'longitude', 'permit'], axis = 1) \n",
    "#had to drop date_recorded because the tree does not allow for datetime values\n",
    "train = pd.DataFrame(train)\n",
    "train.dropna\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note from Natasha:\n",
    "\n",
    "Not sure if we can actually drop values from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(['date_recorded', 'latitude', 'longitude', 'permit'], axis = 1) \n",
    "test = pd.DataFrame(test)\n",
    "test.dropna\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (41580, 16)\n",
      "X_test : (17820, 16)\n",
      "y_train : (41580,)\n",
      "y_test : (17820,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size = 0.30, random_state = 1)\n",
    "print(\"X_train : \" + str(X_train.shape))\n",
    "print(\"X_test : \" + str(X_test.shape))\n",
    "print(\"y_train : \" + str(y_train.shape))\n",
    "print(\"y_test : \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def GS(a,b):\n",
    "    \"\"\"Function that received two parameters; first: a binary variable representing 0=good and 1=bad, and then a second variable with the prediction of the first variable, the second variable can be continuous, integer or binary - continuous is better. Finally, the function returns the GINI Coefficient of the two lists.\"\"\"    \n",
    "    from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n",
    "    false_positive_rate, recall, thresholds = roc_curve(a, b)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    gini = 2*roc_auc_score(a,b)-1\n",
    "    return gini\n",
    "\n",
    "def KS(b,a):  \n",
    "    \"\"\"Function that received two parameters; first: a binary variable representing 0=good and 1=bad, and then a second variable with the prediction of the first variable, the second variable can be continuous, integer or binary - continuous is better. Finally, the function returns the KS Statistics of the two lists.\"\"\"\n",
    "    try:\n",
    "        tot_bads=1.0*sum(b)\n",
    "        tot_goods=1.0*(len(b)-tot_bads)\n",
    "        elements = zip(*[a,b])\n",
    "        elements = sorted(elements,key= lambda x: x[0])\n",
    "        elements_df = pd.DataFrame({'probability': b,'gbi': a})\n",
    "        pivot_elements_df = pd.pivot_table(elements_df, values='probability', index=['gbi'], aggfunc=[sum,len]).fillna(0)\n",
    "        max_ks = perc_goods = perc_bads = cum_perc_bads = cum_perc_goods = 0\n",
    "        for i in range(len(pivot_elements_df)):\n",
    "            perc_goods =  (pivot_elements_df.iloc[i]['len'] - pivot_elements_df.iloc[i]['sum']) / tot_goods\n",
    "            perc_bads = pivot_elements_df.iloc[i]['sum']/ tot_bads\n",
    "            cum_perc_goods += perc_goods\n",
    "            cum_perc_bads += perc_bads\n",
    "            A = cum_perc_bads-cum_perc_goods\n",
    "            if abs(A['probability']) > max_ks:\n",
    "                max_ks = abs(A['probability'])\n",
    "    except:\n",
    "        max_ks = 0\n",
    "    return max_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_method(X_train, y_train, X_test, y_test, method):  \n",
    "    \"\"\" Function to redirect call to the desired method \"\"\"\n",
    "    if method == 'DT': # Decision Tree Classifier\n",
    "        return DT(X_train, y_train, X_test, y_test)    \n",
    "\n",
    "    elif method == 'RFC': # Random Forest Classifier\n",
    "        return RFC(X_train, y_train, X_test, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DT(X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    Decision Tree Classifier\n",
    "    \"\"\"\n",
    "    logr = DecisionTreeClassifier(min_samples_split=20, random_state=99).fit(X_train, Y_train)\n",
    "    y_pred_train = logr.predict(X_train)\n",
    "    y_pred_test = logr.predict(X_test)\n",
    "    a = logr.score(X_test, Y_test)\n",
    "    return {'model':logr ,'accuracy':a }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RFC(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Random Forest Classifier\n",
    "    \"\"\"\n",
    "    rfr = RandomForestClassifier(n_estimators=1000, min_samples_split=2).fit(X_train, y_train)\n",
    "    y_pred_train = rfr.predict(X_train)\n",
    "    y_pred_test = rfr.predict(X_test)\n",
    "    a = rfr.score(X_test, y_test)\n",
    "    return {'model':rfr,'accuracy':a }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'accuracy': 0.7872053872053872}\n"
     ]
    }
   ],
   "source": [
    "#Decision Random Forest\n",
    "dict_trained_model = train_method(X_train, y_train, X_test, y_test,\"RFC\")\n",
    "print(dict_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iris.pdf'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "dict_trained_model = train_method(X_train, y_train, X_test, y_test,\"DT\")\n",
    "print(dict_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "X = X_train\n",
    "y = y_train\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(X, y)\n",
    "pred1 = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SubmissionFormat.csv')\n",
    "predictions = pd.DataFrame(data=pred1, index=None, columns=['status_group'], dtype=None)\n",
    "#ID = pd.DataFrame(data=ID, index=None, columns=['id'], dtype=None)\n",
    "comb = pd.concat([df['id'], predictions], axis=1)\n",
    "\n",
    "comb['status_group'] = comb['status_group'].replace([0], 'functional')\n",
    "comb['status_group'] = comb['status_group'].replace([1], 'functional needs repair')\n",
    "comb['status_group'] = comb['status_group'].replace([2], 'non functional')\n",
    "\n",
    "comb.to_csv('output_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52449</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24806</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28965</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36301</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54122</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785  non functional\n",
       "1  51630      functional\n",
       "2  17168  non functional\n",
       "3  45559  non functional\n",
       "4  49871      functional\n",
       "5  52449      functional\n",
       "6  24806  non functional\n",
       "7  28965  non functional\n",
       "8  36301  non functional\n",
       "9  54122      functional"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "nu <= 0 or nu > 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-389-c3b5c12f2d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNuSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNuSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: nu <= 0 or nu > 1"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "clf = NuSVC(0)\n",
    "clf.fit(X_train, y_train) \n",
    "print(clf.predict(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestClassifier(n_estimators=1000, min_samples_split=2).fit(X_train, y_train)\n",
    "y_pred_train = rfr.predict(X_train)\n",
    "pred = y_pred_test = rfr.predict(test)\n",
    "#print('accuracy:', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the two into submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SubmissionFormat.csv')\n",
    "predictions = pd.DataFrame(data=pred, index=None, columns=['status_group'], dtype=None)\n",
    "#ID = pd.DataFrame(data=ID, index=None, columns=['id'], dtype=None)\n",
    "comb = pd.concat([df['id'], predictions], axis=1)\n",
    "\n",
    "comb['status_group'] = comb['status_group'].replace([0], 'functional')\n",
    "comb['status_group'] = comb['status_group'].replace([1], 'functional needs repair')\n",
    "comb['status_group'] = comb['status_group'].replace([2], 'non functional')\n",
    "\n",
    "comb.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging meta-estimator\n",
    "\n",
    "In ensemble algorithms, bagging methods form a class of algorithms which build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction. These methods are used as a way to reduce the variance of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. In many cases, bagging methods constitute a very simple way to improve with respect to a single model, without making it necessary to adapt the underlying base algorithm. As they provide a way to reduce overfitting, bagging methods work best with strong and complex models (e.g., fully developed decision trees), in contrast with boosting methods which usually work best with weak models (e.g., shallow decision trees).\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely randomised trees - did not perform well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In extremely randomized trees (see ExtraTreesClassifier and ExtraTreesRegressor classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = make_blobs(n_samples=50000, n_features=16, centers=100, random_state=0)\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=6, random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "scores = cross_val_score(clf, X_train, y_train)\n",
    "scores.mean()                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = rfr.predict(X_train)\n",
    "pred = y_pred_test = clf.predict(test)\n",
    "predictions = pd.DataFrame(data=pred, index=None, columns=['status_group'], dtype=None)\n",
    "#ID = pd.DataFrame(data=ID, index=None, columns=['id'], dtype=None)\n",
    "comb = pd.concat([df['id'], predictions], axis=1)\n",
    "\n",
    "comb['status_group'] = comb['status_group'].replace([0], 'functional')\n",
    "comb['status_group'] = comb['status_group'].replace([1], 'functional needs repair')\n",
    "comb['status_group'] = comb['status_group'].replace([2], 'non functional')\n",
    "\n",
    "comb.to_csv('output_clf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X_test, y_test)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X_test, y_test)\n",
    "scores.mean() > 0.78 #compare to random forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
